---
title: "Tarea 4"
output:
  html_document:
    df_print: paged
---

![](banner.png)

<center>

<h1>Tarea 4: Bayesian Inference</h1>

</center>

<center><strong>CC6104: Statistical Thinking</strong></center>

#### **Integrantes :**

-   Tamara Marciel
-   Vicente Pinochet

#### **Cuerpo Docente:**

-   Profesor: Felipe Bravo M.
-   Auxiliar: Martín Paredes, Benjamín Farías
-   Ayudantes: Scarleth Betancurt, Emilio Díaz, Kevin Iturra, Renzo Zanca

### **Índice:**

1.  [Objetivo](#id1)
2.  [Instrucciones](#id2)
3.  [Referencias](#id3)
4.  [Elaboración de Código](#id5)

### **Objetivo**<a name="id1"></a>

Bienvenides a la cuarta tarea del curso Statistical Thinking. Esta tarea tiene como objetivo evaluar los contenidos teóricos de la primera parte del curso, los cuales se enfocan principalmente en introducirlos en la estadística bayesiana. Si aún no han visto las clases, se recomienda visitar los enlaces de las referencias.

La tarea consta de una parte práctica con el fin de introducirlos a la programación en R enfocada en el análisis estadístico de datos.

### **Instrucciones:**<a name="id2"></a>

-   La tarea se realiza en grupos de **máximo 2 personas**. Pero no existe problema si usted desea hacerla de forma individual.
-   La entrega es a través de u-cursos a más tardar el día estipulado en la misma plataforma. A las tareas atrasadas se les descontará un punto por día.
-   El formato de entrega es este mismo **Rmarkdown** y un **html** con la tarea desarrollada. Por favor compruebe que todas las celdas han sido ejecutadas en el archivo html.
-   Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación.
-   No serán revisadas tareas desarrolladas en Python.
-   Está **PROHIBIDO** la copia o compartir las respuestas entre integrantes de diferentes grupos.
-   Pueden realizar consultas de la tarea a través de U-cursos y/o del canal de Discord del curso.

### **Referencias:**<a name="id3"></a>

Slides de las clases:

-   [Introduction to Bayesian Inference](https://github.com/dccuchile/CC6104/blob/master/slides/3_1_ST-bayesian.pdf)
-   [Summarizing the Posterior](https://github.com/dccuchile/CC6104/blob/master/slides/3_2_ST-posterior.pdf)

Videos de las clases:

-   Introduction to Bayesian Inference: [video1](https://youtu.be/Gf2uuElPH0g) [video2](https://youtu.be/5ZZ3PTPdZQw) [video3](https://youtu.be/d_jXwM_-5jc) [video4](https://youtu.be/yZW1V3X4J94) [video5](https://youtu.be/-fw0ktR7psM) [video6](https://youtu.be/0oK9M82sw8Q) [video7](https://youtu.be/u7Qdw5rDDDU)
-   Summarizing the Posterior: [video1](https://youtu.be/67o8wcZsgtk) [video2](https://youtu.be/Xr8S1Uv_5GQ) [video3](https://youtu.be/XJKyW4tYp_0) [video4](https://youtu.be/OMipgV727wo)

Documentación:

-   [rethinking](https://github.com/rmcelreath/rethinking)
-   [tidyr](https://tidyr.tidyverse.org)
-   [purrr](https://purrr.tidyverse.org)
-   [dplyr](https://dplyr.tidyverse.org)
-   [ggplot2](https://ggplot2.tidyverse.org/)

#Elaboración de Código<a name="id5"></a>

En la siguiente sección deberá resolver cada uno de los experimentos computacionales a través de la programación en R. Para esto se le aconseja que cree funciones en R, ya que le facilitará la ejecución de gran parte de lo solicitado.

Para el desarrollo preste mucha atención en los enunciados, ya que se le solicitará la implementación de métodos sin uso de funciones predefinidas. Por otro lado, Las librerías permitidas para desarrollar de la tarea 4 son las siguientes:

```{r}
# Manipulación de estructuras
library(tidyverse)
library(dplyr)
library(tidyr)
library(purrr)

# Para realizar plots
library(scatterplot3d)
library(ggplot2)
library(plotly)

# Manipulación de varios plots en una imagen.
library(gridExtra)

# Análisis bayesiano
library("rethinking")
```

Si no tiene instalada la librería “rethinking”, ejecute las siguientes líneas de código para instalar la librería:

```{r}
install.packages("rethinking")
```

En caso de tener problemas al momento de instalar la librería con el código anterior, utilice las siguiente chunk:

```{r}
install.packages(c("mvtnorm","loo","coda"), repos="https://cloud.r-project.org/",dependencies=TRUE)
options(repos=c(getOption('repos'), rethinking='http://xcelab.net/R'))
install.packages('rethinking',type='source')
```

### Pregunta 1:

Un conjunto de carteros aburridos de las mordidas de perros ha decidido realizar un catastro de mordidas recibidas por los empleados de su empresa en un periodo de 8 meses, planeando en base a estos datos realizar inferencia bayesiana. Los datos de las mordidas estas datos por el dataset `no+mordidas.csv`, en donde cada fila representa las mordidas recibidas por diferentes carteros y las columnas señalan si fue mordido o no el cartero en los meses de estudio (si fue mordido es señalado con un 1, de lo contrario es señalado con un 0). Cabe señalar que un cartero no puede ser mordido mas de una vez al mes, ya que el damnificado recibe licencia de todo un mes tras la mordida, reincorporándose el siguiente mes al trabajo.

```{r}
dataMordidas <- read.csv("no_mordidas.csv", header = TRUE)
```

-   [] Uno de los carteros le comenta que, según él, lo han mordido 6 de cada 10 veces, y le recomienda usar esta información como antecedente para su inferencia. Para ello considere como prior la distribución gausseana de media 0.6 y desviación estándar 0.05. Programe el método grid approximation para 1, 2, 4 y 8 meses. ¿Como van cambiando las curvas posterior?

```{r}
cols <- c("bites_month_1", "bites_month_2", "bites_month_3",
          "bites_month_4", "bites_month_5", "bites_month_6",
          "bites_month_7", "bites_month_8")

grid_len <- 100
p_grid <- 
prior <- 

posteriors <- c()
counted.months <- c()
p_grids <- rep(p_grid, 4)

for (n in c(1, 2, 4, 8)) {
  x <- # total de mordidas
  
  likelihood <- 
  unstd.posterior <- 
  posterior <- 
  
  posteriors <- c(posteriors, posterior)
  counted.months <- c(counted.months, rep(n, grid_len))
}

post.df <- data.frame("grid"=p_grids, "posterior"=posteriors, "months"=counted.months)

ggplot(post.df) +
  geom_line(aes(x=grid, y=posterior)) +
  facet_grid(months ~ .)
```

**Respuesta:**

-   [] Vuelva a aplicar grid approximation como el parte anterior, pero esta vez con prior uniforme y compare los resultados. ¿Qué puede decir sobre la elección de los priors?

```{r}
prior <- 
posteriors <- c()

for (n in c(1, 2, 4, 8)) {
  x <- 
  
  likelihood <- 
  unstd.posterior <- 
  posterior <- 
  
  posteriors <- c(posteriors, posterior)
}

post.df$posterior2 <- posteriors

ggplot(post.df) +
  geom_line(aes(x=grid, y=posterior)) +
  geom_line(aes(x=grid, y=posterior2), color="red") +
  facet_grid(months ~ .)
```

**Respuesta:**

-   [] Repita el mismo analisis anterior pero utilizando el metodo de Laplace (no necesita programar el metodo, puede utilizar la libreria "rethinking"). ¿Cómo se comparan con los resultados anteriores?

```{r}
# for (n in c(1, 2, 4, 8)) {
#  res <- quap(
#    alist(
#      W ~  # binomial likelihood
#      p ~  # uniform pior
#    ),
#    data = list(W=sum(dataMordidas[, cols[1:n]]),L=n*250-sum(dataMordidas[, cols[1:n]])) )
  
#  df <- precis(res)
#  curve(dnorm(x, df$mean, df$sd), lty=2, add=FALSE)
#}
```

**Respuesta:**

-   [] Grafique la densidad de la posterior y encuentre la proporción de los siguientes defined boundaries:

-   [ ] $(0, 0.35)$

-   [ ] $(0.35, 0.45)$

-   [ ] $(0.45, 1)$

¿Cómo puede interpretar los resultados?

```{r}
grid_len <- 1000
p_grid <- 

prior <- 

likelihood <- 

unstd.posterior <- 

posterior <- 

samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)

dens(samples)
```

Intervalos:

```{r}
# fracción de valores <0.35
```

```{r}
# fracción de valores entre 0.35 y 0.45
```

```{r}
# fracción de valores >0.45
```

**Respuesta:**

\-[] Calcule un intervalo de credibilidad al $50%$, $75%$ y $95%$. ¿Como se puede interpretar los resultados? ¿Cual podría ser un problema al usar intervalos de credibilidad?

Intervalo $50\%$:

```{r}

```

Intervalo $75\%$

```{r}

```

Intervalo $95\%$

```{r}

```

**Respuesta:**

-   [ ] Genere los intervalos HDPI para $50%$, $75%$ y $95%$, compárelos con los intervalos de credibilidad de la parte anterior. ¿En que se diferencian los intervalos de credibilidad con los HDPI?

Intervalo $50\%$:

```{r}

```

Intervalo $75\%$

```{r}

```

Intervalo $95\%$

```{r}

```

**Respuesta:**

-   [ ] Utilizando la posterior obtenida en la parte anterior, simule 10.000 réplicas de registros de mordidas. Compare la distribución del ratio de carteros mordidos predichos a partir de las réplicas con el ratio real de los datos. ¿El modelo se ajusta bien a los datos? Es decir, ¿la distribución de las predicciones incluye la observación real como resultado central y probable?

```{r}
ratio.real <- 
samples <- 

ggplot() +
  geom_density(aes(samples)) +
  geom_vline(aes(xintercept=ratio.real), color="red")
```

**Respuesta:**

-   [ ] Escoja cualquier par de meses concecutivos y obtenga la posterior de que una persona que fue mordida en el primer mes, sea mordida nuevamente en el segundo mes. Para esto, se recomienda comenzar buscando los carteros que fueron mordidos el primer mes y en base a estos generar una búsqueda indexada para obtener el número solicitado. Hecho esto simule ese número carteros mordidos 10.000 veces. De los resultados obtenidos, compare el recuento de carteros mordidos con el recuento real. ¿Cómo se ve el modelo desde este punto de vista?

```{r}


```

**Respuesta:**

------------------------------------------------------------------------

### Pregunta 2:

En esta pregunta se trabajara con el dataset "notas.csv" el cual contiene las notas históricas de un curso desconocido. Suponga que los datos vienen de una distribución $\mathcal{N}(\mu,\sigma^2)$, el objetivo de la pregunta es estudiar el comportamiento de los datos y los posibles valores de $\mu,\sigma$ mediante técnicas de inferencia Bayesiana.

Usted sabe un dato extra sobre la información, $\sigma \in [0.5,1.5]$ y, además, tiene una fuerte creencia a que es mas probable encontrar la desviación estándar real entre $[0.5,1]$ que en $(1,1.5]$.

-   [ ] Modifique el siguiente codigo que permite realizar una grid approximation para $2$ parámetros. Proponga priors para $\mu$ y $\sigma$, justifique su elección.

```{r}
# Leer información
data_notas <- read.csv("notas.csv")
head(data_notas)

# Función para crear likelihood dado mu y sigma
grid_function <- function(mu, sigma) {
  # Log-likelihood basado en distribución normal
  sum(dnorm(data_notas$Notas, mean = mu, sd = sigma, log = TRUE))
}

# Valores de la grilla
grid_mu <- seq(mean(data_notas$Notas, na.rm = TRUE) - 3, 
               mean(data_notas$Notas, na.rm = TRUE) + 3, length.out = 100)
grid_sigma <- seq(0.5, 1.5, length.out = 100)

# Crear grilla 2D
data_grid <- expand_grid(grid_mu, grid_sigma)

# Calcular likelihood para cada par (mu, sigma)
data_grid <- data_grid %>%
  mutate(likelihood = map2_dbl(grid_mu, grid_sigma, grid_function))

# Priors
prior_mu <- rep(1 / length(grid_mu), length(grid_mu)) # Uniforme para mu
prior_sigma <- ifelse(grid_sigma <= 1, 0.75, 0.25)    # Ponderación más alta para [0.5, 1]
prior_sigma <- prior_sigma / sum(prior_sigma)         # Normalizar prior_sigma

# Crear columnas separadas para priors en data_grid
data_grid <- data_grid %>%
  mutate(prior_mu = prior_mu[match(grid_mu, unique(grid_mu))],
         prior_sigma = prior_sigma[match(grid_sigma, unique(grid_sigma))],
         prior = prior_mu * prior_sigma)

# Calcular posterior no estandarizado
data_grid <- data_grid %>%
  mutate(unstd_posterior = likelihood + log(prior), # Log-transformación para estabilidad numérica
         posterior = exp(unstd_posterior - max(unstd_posterior))) %>% # Ajuste para evitar underflow
  mutate(posterior = posterior / sum(posterior)) # Normalización del posterior

# Mostrar las primeras filas del dataframe resultante
head(data_grid)
```

**Respuesta:**

1.  **Prior para** $\mu$ (media):\
    Dado que no tenemos información previa sobre la ubicación de la media, se asume una distribución uniforme para $\mu$. Esto refleja una incertidumbre inicial equitativa sobre los posibles valores de la media.

2.  **Prior para** $\sigma$ (desviación estándar):\
    Sabemos que $\sigma \in [0.5, 1.5]$, con una mayor probabilidad en $[0.5, 1]$ que en $(1, 1.5]$.\
    Para reflejar esta creencia, asignamos un prior con un peso de **0.75** para valores en $[0.5, 1]$ y **0.25** para valores en $(1, 1.5]$. Este prior sesgado refleja nuestra expectativa sobre $\sigma$.

-   [ ] Tras haber ejecutado el código de la parte anterior ejecute el siguiente, ¿Que puede decir de los valores de la distribución? Se recomienda hacer modificaciones en el código para realizar un mejor análisis y estudio.

```{r}

# Punto de referencia
# Se recomienda cambiar estos valores por unos adecuados que le permitan estudiar
# Los valores de la distribución de mejor manera
valor_x <- 1
valor_y <- 1

# Grafico

punto_comparacion <- tibble(x = valor_x, y = valor_y)

plt <- data_grid %>%
  ggplot(aes(x = grid_mu, y = grid_sigma)) +
  geom_raster(aes(fill = posterior),
    interpolate = T
  )+ 
  geom_point(x = valor_x, y = valor_y, size = 1.3,color="white")+
  geom_label(
    data = punto_comparacion, aes(x, y),
    label = "Punto Comparación",
    fill = "green",
    color = "black",
    nudge_y = 0, # Este parametro desplaza la caja por el eje y
    nudge_x = 1 # Este parametro desplaza la caja por el eje x
  )+
  scale_fill_viridis_c() +
  labs(
    title = "Posterior para Mean y Standard Deviation",
    x = expression(mu ["Mean"]),
    y = expression(sigma ["Standar Deviation"])
  ) +
  theme(panel.grid = element_blank())

plt
```

**Respuesta:**

-   [ ] A continuación se presenta un código que permite realizara la distribución dada por sampling from grid approximation ¿Para que sirve este proceso? ¿Que puede deducir del gráfico?

```{r}

# Codificamos los datos
x <- 1:length(data_grid$posterior)

# Sampleamos los indices
posterior_samples_aux <- sample(x,size = 1e4, replace = T, prob = data_grid$posterior)

# Obtenemos los verdaderos valores de la sampling distribution
posterior_samples <- data_grid[posterior_samples_aux,]

# Obtenemos solos los valores relevantes para la densidad
df <- data.frame(posterior_samples$grid_mu,posterior_samples$grid_sigma)

# Realizamos las densidades
dens(df)
```

**Respuesta:**

------------------------------------------------------------------------

### Pregunta 3: Regresión Lineal Bayesiana

El objetivo de esta pregunta es introducirlo en la aplicación de una regresión bayesiana. Con esto, buscaremos entender como calcular una regresión bayesiana en base al "motor" aproximación de Laplace, revisando como se comporta la credibilidad de sus predicciones y como la regresión lineal puede llegar a mutar a aplicar una transformación en el vector $x$. Para responder esta pregunta centre su desarrollo solo en las clases y las funciones que nos brinda la librería `rethinking`.

Para esta pregunta usaremos el dataset `Pokemon.csv`, que contiene las características de más de 700 personajes.

```{r}
poke.df <- read.csv("Pokemon.csv")
head(poke.df)
```

-   [ ] Defina un modelo de regresión bayesiana para modelar `Sp..Atk` en función de `Attack`, definiendo sus propios priors. Comente cada una de sus asunciones y señale a través de ecuaciones el modelo.
-   [ ] Ajuste el modelo lineal utilizando el método de Laplace approximation. Estudie a través del comando `precis` los resultados obtenidos y coméntelos.
-   [ ] Gráfique el MAP de regresión lineal obtenida, añadiendo al gráfico el intervalo del $95\%$ que se tiene sobre la media y los valores predecidos de la altura. Comente los resultados obtenidos y señale si su modelo logra ser un buen predictor de los valores estudiados.

**Respuesta:**

```{r}
modelo <- alist(
  Sp..Atk ~ dnorm(mu, sigma),
  mu <- alpha + beta * Attack,
  alpha ~ dnorm(100, 20),   # Prior para alpha
  beta ~ dnorm(0, 10),      # Prior para beta
  sigma ~ dexp(1)           # Prior para sigma
)
```

El modelo propuesto busca modelar la relación entre `Sp..Atk` (ataque especial) y `Attack` (ataque físico). Las ecuaciones y los priors asumidos son los siguientes:

**Modelo matemático**:

$$
Sp..Atk_i \sim \mathcal{N}(\mu_i, \sigma) \quad \text{donde} \quad \mu_i = \alpha + \beta \cdot \text{Attack}_i
$$

**Priors definidos**: - $\alpha \sim \mathcal{N}(100, 20)$: Refleja que esperamos un valor promedio de `Sp..Atk` alrededor de 100 con una incertidumbre razonable. - $\beta \sim \mathcal{N}(0, 10)$: Asume inicialmente que no hay una relación fuerte entre `Attack` y `Sp..Atk`. - $\sigma \sim \text{Exponencial}(1)$: Prior para la desviación estándar de los residuos, asegurando positividad y favoreciendo valores pequeños.

```{r}
fit <- map(
  alist(
    Sp..Atk ~ dnorm(mu, sigma),
    mu <- alpha + beta * Attack,
    alpha ~ dnorm(100, 20),
    beta ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = poke.df
)
 
precis(fit)

```

El intercepto ($\alpha$) indica que, para un valor de Attack cercano a 0, el Sp..Atk predicho es 42.41. La pendiente ($\beta$) es 0.39, lo que implica que por cada aumento de una unidad en Attack, el Sp..Atk promedio aumenta en 0.39 unidades. El alto valor de $\sigma$ (29.50) refleja una gran variabilidad no explicada por el modelo.

```{r}
plot_data <- data.frame(Attack = seq(min(poke.df$Attack), max(poke.df$Attack), length.out = 100))
plot_data$mu <- coef(fit)["alpha"] + coef(fit)["beta"] * plot_data$Attack
ggplot() +
  geom_point(aes(x = poke.df$Attack, y = poke.df$Sp..Atk), color = "red") +
  geom_line(aes(x = plot_data$Attack, y = plot_data$mu), color = "orange") +
  geom_ribbon(aes(x = plot_data$Attack, ymin = plot_data$mu - 1.96 * coef(fit)["sigma"], 
                  ymax = plot_data$mu + 1.96 * coef(fit)["sigma"]), alpha = 0.3, fill = "orange")
```

### Comentarios sobre el gráfico

1.  **Relación positiva moderada**:

    -   La línea naranja representa el modelo de regresión ajustado. Se observa una tendencia positiva entre `Attack` y `Sp..Atk`, lo que confirma que al aumentar el valor de `Attack`, también aumenta el valor promedio de `Sp..Atk`.

2.  **Alta dispersión en los datos**:

    -   Los puntos rojos (datos reales) están altamente dispersos alrededor de la línea de regresión. Esto indica que el modelo no captura toda la variabilidad en los datos. La dispersión sugiere que existen otros factores (además de `Attack`) que influyen significativamente en `Sp..Atk`.

3.  **Intervalos de credibilidad amplios**:

    -   Las áreas sombreadas en naranja representan los intervalos de credibilidad al **95%**. La amplitud considerable de estos intervalos refuerza la idea de alta incertidumbre en las predicciones del modelo.

4.  **Valores atípicos**:

    -   Hay puntos alejados significativamente de la línea ajustada, lo que podría corresponder a Pokémon con características muy específicas (por ejemplo, Pokémon legendarios o de tipos especializados).

    1.  **Limitaciones del modelo lineal**:

        -   Aunque el modelo lineal captura la tendencia general, parece insuficiente para describir completamente la relación entre `Attack` y `Sp..Atk`. Un modelo más complejo podría mejorar la capacidad predictiva.

        El modelo muestra que existe una relación positiva, pero no captura toda la variabilidad ni explica los datos de manera óptima debido a la alta dispersión y otros factores omitidos.

<hr />

<p style="text-align: center;">

A work by <a href="https://github.com/dccuchile/CC6104">CC6104</a>

</p>

<!-- Add icon library -->

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css">

<!-- Add font awesome icons -->

<p style="text-align: center;">

<a href="https://github.com/dccuchile/CC6104"><i class="fab fa-github" style='font-size:30px'></i></a>

</p>

<p style="text-align: center;">

<a href="https://discord.gg/XCbQvGs3Uf"><i class="fab fa-discord" style='font-size:30px'></i></a>

</p>

 
